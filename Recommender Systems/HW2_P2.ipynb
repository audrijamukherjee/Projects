{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load Data, Generate noisy images and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "#make noisy images by flipping 0.03*no. of pixels per image\n",
    "noise_factor = 0.03\n",
    "total=28*28\n",
    "#generate floor(0.03*28*28) pixel indices to flip\n",
    "temp_noisy1=np.copy(x_train)\n",
    "temp_noisy2=np.copy(x_train)\n",
    "x_test_noisy=np.copy(x_test)\n",
    "for image in range(0,len(temp_noisy1)):\n",
    "    indices1=np.random.random_integers(0,total-1,size=int(total*noise_factor))\n",
    "    indices2 = np.random.random_integers(0, total - 1, size=int(total * noise_factor))\n",
    "    for i in indices1:\n",
    "        temp_noisy1[image,i/28,i%28]=255-temp_noisy1[image,i/28,i%28]\n",
    "    for i in indices2:\n",
    "        temp_noisy2[image, i / 28, i % 28] = 255 - temp_noisy2[image, i / 28, i % 28]\n",
    "x_train_noisy = np.concatenate((temp_noisy1,temp_noisy2),axis=0)\n",
    "\n",
    "for image in range(0, len(x_test_noisy)):\n",
    "    indices3 = np.random.random_integers(0, total - 1, size=int(total * noise_factor))\n",
    "    for i in indices3:\n",
    "        x_test_noisy[image, i / 28, i % 28] = 255 - x_test_noisy[image, i / 28, i % 28]\n",
    "\n",
    "#normalize the pixel values\n",
    "x_train_noisy = x_train_noisy.astype('float32') / 255.\n",
    "x_test_noisy = x_test_noisy.astype('float32') / 255.\n",
    "x_train= x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Method to plot best and worst 10 digits based on RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_digits(x_test,decoded_imgs):\n",
    "    total=28*28\n",
    "    #to calculate RMSE of each image for the final predicted op\n",
    "    RMSE=np.zeros(len(x_test))\n",
    "    temp=np.square(x_test-decoded_imgs)\n",
    "    for i in range(0,len(x_test)):\n",
    "        RMSE[i]=math.sqrt(np.sum(temp[i])/total)\n",
    "    sorted_RMSE_indices=RMSE.argsort()\n",
    "    best_10=sorted_RMSE_indices[:10]\n",
    "    worst_10=sorted_RMSE_indices[-10:][::-1]\n",
    "\n",
    "    print (\"BEST 10 are indices are: \",best_10)\n",
    "    print (\"WORST 10 are indices are: \",worst_10)\n",
    "\n",
    "    #plot best and worst 10 predictions\n",
    "    #plot best and worst 10 predictions\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure()\n",
    "    for i in range(n):\n",
    "        # display best original\n",
    "        ax = plt.subplot(4, n, i + 1)\n",
    "        plt.imshow(x_test_noisy[best_10[i]].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        #display best reconstructed\n",
    "        ax = plt.subplot(4, n, i + 1+n)\n",
    "        plt.imshow(decoded_imgs[best_10[i]].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display worst original\n",
    "        ax = plt.subplot(4, n, i + 1+2*n)\n",
    "        plt.imshow(x_test_noisy[worst_10[i]].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        #display worst reconstructed\n",
    "        ax = plt.subplot(4, n, i + 1 + 3*n)\n",
    "        plt.imshow(decoded_imgs[worst_10[i]].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.suptitle(\"top rows = 10 best digits (original,reconstructed) \\n bottom rows = 10 worst digits (original,reconstructed)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Autoencoder- Architecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ARCHITECTURE 1 - As in blog\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  \n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy',metrics=['mse'])\n",
    "\n",
    "autoencoder.fit(x_train_noisy, np.concatenate((x_train,x_train),axis=0),\n",
    "                epochs=12, \n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])\n",
    "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "plot_digits(x_test,decoded_imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot- Autoencoder 1\n",
    "<img src=\"Arch1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Autoencoder- Architecture 2: Changing number of filters from 32 to 16 in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ARCHITECTURE 2:Changing number of filters from 32 to 16 in each layer\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  \n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy',metrics=['mse'])\n",
    "\n",
    "autoencoder.fit(x_train_noisy, np.concatenate((x_train,x_train),axis=0), \n",
    "                epochs=12, \n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])\n",
    "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "plot_digits(x_test,decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot- Autoencoder 2\n",
    "<img src=\"Arch2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Autoencoder- Architecture 3: Changing size of receptive field to 5X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Architecture 3: Changing size of receptive field to 5X5\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  \n",
    "\n",
    "x = Conv2D(32, (5, 5), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (5, 5), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (5, 5), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy',metrics=['mse'])\n",
    "\n",
    "autoencoder.fit(x_train_noisy, np.concatenate((x_train,x_train),axis=0),\n",
    "                epochs=12,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])\n",
    "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "plot_digits(x_test,decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot- Autoencoder 3\n",
    "<img src=\"Arch3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Autoencoder- Architecture 4: Changing number of hidden layers, adding one more hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Architecture 4: Changing number of hidden layers, adding one more hidden layer\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  \n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#Adding a hidden layer here\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "#Adding a hidden layer here\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy',metrics=['mse'])\n",
    "\n",
    "autoencoder.fit(x_train_noisy, np.concatenate((x_train,x_train),axis=0),\n",
    "                epochs=12,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])\n",
    "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "plot_digits(x_test,decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot- Autoencoder 4\n",
    "<img src=\"Arch4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tried other losses like Cosine similarity and mean_squared_logarithmic_error. MSLE worked better than cosine similarity. But for both MSE was much higher than binary_crossentropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create the MSE curves for the 4 architectures, MSE vs per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "epochs=range(1,13)\n",
    "\n",
    "#Autoencoder 1\n",
    "mse_arch1=[0.0210, 0.0072, 0.0059, 0.0051 , 0.0047 , 0.0044 , 0.0041 , 0.0040 ,0.0038 ,0.0037 ,0.0036 ,0.0035 ]\n",
    "plt.figure()\n",
    "plt.title('Autoencoder 1- Test MSE over epochs')\n",
    "plt.xlabel('Number of epochs (# of training samples=120,000*epochs)')\n",
    "plt.ylabel('Test MSE')\n",
    "plt.xticks(epochs,epochs)\n",
    "plt.plot(epochs,mse_arch1)\n",
    "plt.show()\n",
    "\n",
    "#Autoencoder 2\n",
    "mse_arch2=[0.0221 ,0.0088 , 0.0072 , 0.0063 , 0.0058 , 0.0054 ,0.0052 ,0.0050 ,0.0048 ,0.0047 ,0.0046 , 0.0044 ]  #PUT VALUES\n",
    "plt.figure()\n",
    "plt.title('Autoencoder 2- Test MSE over epochs')\n",
    "plt.xlabel('Number of epochs (# of training samples=120,000*epochs)')\n",
    "plt.ylabel('Test MSE')\n",
    "plt.xticks(epochs,epochs)\n",
    "plt.plot(epochs,mse_arch1)\n",
    "plt.show()\n",
    "\n",
    "#Autoencoder 3\n",
    "mse_arch3=[0.0188 , 0.0068 , 0.0055 , 0.0048 ,0.0044 ,0.0041 , 0.0039 ,0.0038 ,0.0036 ,0.0035, 0.0034 ,0.0033 ]\n",
    "plt.figure()\n",
    "plt.title('Autoencoder 3- Test MSE over epochs')\n",
    "plt.xlabel('Number of epochs (# of training samples=120,000*epochs)')\n",
    "plt.ylabel('Test MSE')\n",
    "plt.xticks(epochs,epochs)\n",
    "plt.plot(epochs,mse_arch1)\n",
    "plt.show()\n",
    "\n",
    "#Autoencoder 4\n",
    "mse_arch4=[0.0210, 0.0078 ,  0.0062 , 0.0053 ,0.0048 ,0.0045 ,0.0042 ,0.0040 ,0.0039 ,0.0037 ,0.0036 ,0.0035 ]\n",
    "plt.figure()\n",
    "plt.title('Autoencoder 4- Test MSE over epochs')\n",
    "plt.xlabel('Number of epochs (# of training samples=120,000*epochs)')\n",
    "plt.ylabel('Test MSE')\n",
    "plt.xticks(epochs,epochs)\n",
    "plt.plot(epochs,mse_arch1)\n",
    "plt.show()\n",
    "\n",
    "#All together\n",
    "plt.figure()\n",
    "label=['Autoencoder 1','Autoencoder 2','Autoencoder 3','Autoencoder 4']\n",
    "plt.figure()\n",
    "plt.title('All autoencoders - Test MSE over epochs')\n",
    "plt.xlabel('Number of epochs (# of training samples=120,000*epochs)')\n",
    "plt.ylabel('Test MSE')\n",
    "plt.xticks(epochs,epochs)\n",
    "plt.plot(epochs,mse_arch1,alpha=1.0,marker='o')\n",
    "plt.plot(epochs,mse_arch2,alpha=1.0,marker='.')\n",
    "plt.plot(epochs,mse_arch3,alpha=1.0,marker='*')\n",
    "plt.plot(epochs,mse_arch4,alpha=1.0,marker=',')\n",
    "plt.legend(label,loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot MSE vs #epochs for Autoencoder 1,2,3,4. Plot 5 is MSEs plotted for all the 4 autoencoders\n",
    "<img src=\"MSE_Arch1.png\">\n",
    "<img src=\"MSE_Arch2.png\">\n",
    "<img src=\"MSE_Arch3.png\">\n",
    "<img src=\"MSE_Arch4.png\">\n",
    "<img src=\"MSE_All_Arch.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As seen from plot, Architecture 2(reduced number of filters per layer) works worst among these. MSE for architecture 1,4 is comparable. Architecture 3 (larger receptive field) works slightly better than 1,4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Autoencoder Architecture Details:\n",
    "\n",
    "ARCHITECTURE 1\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "===================================================\n",
    "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 14, 14, 32)        9248      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 7, 7, 32)          9248      \n",
    "_________________________________________________________________\n",
    "up_sampling2d_1 (UpSampling2 (None, 14, 14, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 14, 14, 32)        9248      \n",
    "_________________________________________________________________\n",
    "up_sampling2d_2 (UpSampling2 (None, 28, 28, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 28, 28, 1)         289       \n",
    "===================================================\n",
    "\n",
    "ARCHITECTURE 2\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "===================================================\n",
    "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2320      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 7, 7, 16)          2320      \n",
    "_________________________________________________________________\n",
    "up_sampling2d_1 (UpSampling2 (None, 14, 14, 16)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 14, 14, 16)        2320      \n",
    "_________________________________________________________________\n",
    "up_sampling2d_2 (UpSampling2 (None, 28, 28, 16)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 28, 28, 1)         145       \n",
    "===================================================\n",
    "\n",
    "ARCHITECTURE 3\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "===================================================\n",
    "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 14, 14, 32)        25632     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 7, 7, 32)          25632     \n",
    "_________________________________________________________________\n",
    "up_sampling2d_1 (UpSampling2 (None, 14, 14, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 14, 14, 32)        25632     \n",
    "_________________________________________________________________\n",
    "up_sampling2d_2 (UpSampling2 (None, 28, 28, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 28, 28, 1)         801       \n",
    "===================================================\n",
    "\n",
    "ARCHITECTURE 4\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "===================================================\n",
    "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 14, 14, 32)        9248      \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 14, 14, 32)        9248      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 7, 7, 32)          9248      \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 7, 7, 32)          9248      \n",
    "_________________________________________________________________\n",
    "up_sampling2d_1 (UpSampling2 (None, 14, 14, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 14, 14, 32)        9248      \n",
    "_________________________________________________________________\n",
    "up_sampling2d_2 (UpSampling2 (None, 28, 28, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_7 (Conv2D)            (None, 28, 28, 1)         289       \n",
    "==================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
